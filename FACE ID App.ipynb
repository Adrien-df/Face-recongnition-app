{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e76b47",
   "metadata": {},
   "source": [
    "# FACE ID App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f57680",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd248f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from keras_vggface import VGGFace\n",
    "from keras_vggface import utils\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dc09f",
   "metadata": {},
   "source": [
    "## Step 1 : Learning your face "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0a439",
   "metadata": {},
   "source": [
    "Load a few pictures of yourself (5 for example), *alone on the picture*, with your face visible. Name them : image_1.jpg , image_2.jpg etc.\n",
    "\n",
    "Load them in a new folder called \"Your_name\" in the directory \"Raw_images\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c91544",
   "metadata": {},
   "source": [
    "## Face detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d851c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give your name in input, with the first letter in capital letter\n",
    "your_name = 'Adrien'\n",
    "\n",
    "#Number of raw images of yourself you have submitted\n",
    "nb_photos = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2235820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adefo\\AppData\\Local\\Temp/ipykernel_15224/3981687163.py:7: UserWarning: Close the images windows each time one opens \n",
      "  warnings.warn(\"Close the images windows each time one opens \")\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('Face_extract\\\\'+your_name)\n",
    "\n",
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Warning\n",
    "warnings.warn(\"Close the images windows each time one opens \")\n",
    "\n",
    "\n",
    "for j in range(nb_photos):\n",
    "\n",
    "# Read the input image\n",
    "\n",
    "    img = cv2.imread(rf'.\\Raw_images\\\\'+ your_name +'\\image_'+str(j+1)+'.jpg')\n",
    "    cv2.imshow('Visualisation',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Convert into grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 10)\n",
    "\n",
    "# Draw rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "#Save the face\n",
    "    for i in range(len(faces)) :\n",
    "        (x, y, w, h) = faces[i]  \n",
    "        cv2.imwrite(rf'Face_extract\\\\'+your_name +'\\\\face_' +str(j+1)+ '.png', img[y:y+h,x:x+h])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656155e",
   "metadata": {},
   "source": [
    "## Compute the embedding vectors with pre-trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f628cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-trained-model\n",
    "\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d37e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the vectors\n",
    "\n",
    "Vectors = []\n",
    "\n",
    "for i in range(nb_photos):\n",
    "\n",
    "    img = image.load_img(rf'Face_extract\\\\'+your_name +'\\\\face_' +str(i+1)+ '.png', target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = utils.preprocess_input(x, version=1) # or version=2\n",
    "    Vectors.append(model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc6412",
   "metadata": {},
   "source": [
    "# Step 2 : Detect if your face is in a picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c832fb",
   "metadata": {},
   "source": [
    "## Detect all the faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48040f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to picture to test\n",
    "\n",
    "path_to_picture = 'Images\\\\group_with_adrien'\n",
    "\n",
    "#Try this path if you want a picture with many people but non from our group\n",
    "\n",
    "#path_to_picture = 'Images\\\\im1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c41b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(rf''+path_to_picture+'.png')\n",
    "cv2.imshow('Visualisation',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert into grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 10)\n",
    "\n",
    "# Draw rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "faces_identified =[]\n",
    "for i in range(len(faces)) :\n",
    "    \n",
    "    # Save the faces images\n",
    "    (x, y, w, h) = faces[i]  \n",
    "    cv2.imwrite(r'Faces_identified\\\\face_' +str(i)+ '.png', img[y:y+h,x:x+h])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e7d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed them in vectors\n",
    "\n",
    "for i in range(len(faces)) :\n",
    "    \n",
    "    img = image.load_img(rf'Faces_identified\\\\face_' +str(i)+ '.png', target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = utils.preprocess_input(x, version=1)\n",
    "    \n",
    "    faces_identified.append(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accc912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Checking if face in picture\n",
    "\n",
    "def is_in_picture(faces_identified, Vectors):\n",
    "    for element in faces_identified :\n",
    "        avg =0\n",
    "        for i in range(nb_photos) :\n",
    "            avg += np.linalg.norm(np.transpose(element) - np.transpose(Vectors[i]))\n",
    "        if (avg/nb_photos)<100 :\n",
    "             return(True)\n",
    "    return False\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0bb343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_in_picture(faces_identified, Vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
