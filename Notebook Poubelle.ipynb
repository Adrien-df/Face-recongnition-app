{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input image\n",
    "img = cv2.imread(r'.\\Images\\im1.JPG')\n",
    "#img = cv2.imread('Test_detect.jpg')\n",
    "cv2.imshow('Visualisation',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle OS\n",
      " Le num‚ro de s‚rie du volume est D2E6-2C65\n",
      "\n",
      " R‚pertoire de C:\\Users\\adefo\\OneDrive\\Bureau\\Polytechnique\\DSB\\DeepLearningHEC\\Project face detection\n",
      "\n",
      "15/12/2021  10:16    <DIR>          .\n",
      "15/12/2021  10:16    <DIR>          ..\n",
      "15/12/2021  09:55    <DIR>          .ipynb_checkpoints\n",
      "15/12/2021  10:02    <DIR>          Face_extract\n",
      "14/12/2021  18:54         9ÿ844ÿ005 haarcascade_frontalface_default.xml\n",
      "14/12/2021  19:53    <DIR>          Images\n",
      "15/12/2021  10:16            10ÿ341 Notebook.ipynb\n",
      "14/12/2021  21:22    <DIR>          Random_faces\n",
      "15/12/2021  10:00    <DIR>          Raw_images\n",
      "15/12/2021  10:15             5ÿ540 Untitled.ipynb\n",
      "               3 fichier(s)        9ÿ859ÿ886 octets\n",
      "               7 R‚p(s)  89ÿ288ÿ740ÿ864 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give your name in input, with the first letter in capital letter\n",
    "your_name = 'Adrien'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw_images\\Adrien\\image_1.jpg\n"
     ]
    }
   ],
   "source": [
    "print('Raw_images\\\\' +your_name+'\\image_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(rf'Raw_images\\\\' +your_name+'\\image_1.jpg')\n",
    "#img = cv2.imread('Test_detect.jpg')\n",
    "cv2.imshow('Visualisation',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "\n",
    "# Read the input image\n",
    "\n",
    "    img = cv2.imread(rf'Raw_images\\Adrien\\adri_'+str(j+1)+'.jpg')\n",
    "#img = cv2.imread('Test_detect.jpg')\n",
    "    cv2.imshow('Visualisation',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Convert into grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 10)\n",
    "\n",
    "# Draw rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    for i in range(len(faces)) :\n",
    "        (x, y, w, h) = faces[i]  \n",
    "        cv2.imwrite(rf'Face_extract\\Adrien\\face_' +str(j+i)+ '.png', img[y:y+h,x:x+h])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface import VGGFace\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_vggface import utils\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(rf'Face_extract\\Adrien\\face_1.png', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "pred1 = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(rf'Face_extract\\Adrien\\face_2.png', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "pred2 = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(rf'Face_extract\\Adrien\\face_3.png', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "pred3 = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(rf'Face_extract\\Adrien\\face_4.png', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "pred4 = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(rf'Faces_identified\\face_0.png', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "pred_diff = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(rf'Faces_identified\\face_4.png', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "pred_diff_4 = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(rf'Faces_identified\\face_4.png', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "pred_diff_4 = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8329066444539293"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(np.transpose(pred1),np.transpose(pred_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8266126308759164"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(np.transpose(pred2),np.transpose(pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.03894351, ..., 0.        , 0.        ,\n",
       "        7.350588  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.3334885e-03, 5.8810675e-01, 2.5904374e-03, ..., 1.8150498e+00,\n",
       "        3.2854617e-01, 4.3963127e+00]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140.65799"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.transpose(pred1) - np.transpose(pred_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.573883"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.transpose(pred1) - np.transpose(pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.035473"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.transpose(pred1) - np.transpose(pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.4156"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.transpose(pred_diff) - np.transpose(pred_diff_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "194ab7ed5e6231cfffcd6bd5f8a19560af34f33f95d5242f71e532acc25ef6f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
